{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import csv\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/xuhui/10002/Machine_Learning/R-net-master/glove.840B.300d.txt') as f:\n",
    "    word2vec = {}\n",
    "    for index, line in enumerate(f):\n",
    "        line =line.strip().split(' ')\n",
    "        word2vec[line[0]] = np.array(line[1:],dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question():\n",
    "    q_dict ={\n",
    "        'A1':'What is the objective / aim of this paper ?',\n",
    "        'A2':'What problem(s) does this paper address ?',\n",
    "        'A41':'What method / approach does this paper propose ?',\n",
    "        'A51':'What is this method based on ?',\n",
    "        'A61':'How does the proposed method differ from previous methods / approaches ?',\n",
    "        'A42':'What model does this paper propose ?',\n",
    "        'A52':'What is this model based on ?',\n",
    "        'A62':'How does the proposed model differ from previous models ?',\n",
    "        'A43':'What algorithm does this paper propose ?',\n",
    "        'A53':'What is this algorithm based on ?',\n",
    "        'A63':'How does the proposed algorithm differ from previous algorithms ?',\n",
    "        'A44':'What framework does this paper propose ?',\n",
    "        'A54':'What is this framework based on ?',\n",
    "        'A64':'How does the proposed framework differ from previous frameworks ?',\n",
    "        'A45':'What datasetdoes this paper propose ?',\n",
    "        'A7':'What experiment does this paper carry out to evaluate the result ?',\n",
    "        'A81':'What does the result of this paper show(demonstrated by the experiment)',\n",
    "        'A82':'What does the result of this paper show(demonstrated by the experiment)',\n",
    "        'A83':'What does the result of this paper show(demonstrated by the experiment)',\n",
    "        'A10':'How does this result outperform existing work ?' \n",
    "        }\n",
    "    return q_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liter_questions(ques_ID):\n",
    "    return get_question()[ques_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sen_vec(content):\n",
    "    content2vec = np.zeros(300)\n",
    "    for i in content:\n",
    "        content2vec += word2vec.get(i,np.zeros(300))\n",
    "    return content2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "csvFile1 = open('/home/xuhui/10002/Machine_Learning/train.csv', 'r', encoding='utf-8')\n",
    "train_file = csv.reader(csvFile1)\n",
    "for line in train_file:\n",
    "    # 忽略第一行\n",
    "    if train_file.line_num == 1:\n",
    "        continue\n",
    "        \n",
    "    ques_ID = line[0]    \n",
    "    QA_abs = line[1]\n",
    "    answer_text = line[2]\n",
    "    \n",
    "    question = get_liter_questions(ques_ID)\n",
    "    \n",
    "    ques_tokens = nltk.word_tokenize(question)\n",
    "    abs_tokens = nltk.word_tokenize(QA_abs)\n",
    "    ans_tokens = nltk.word_tokenize(answer_text)\n",
    "    \n",
    "    ques_vec = cal_sen_vec(ques_tokens)\n",
    "    abs_vec = cal_sen_vec(abs_tokens)\n",
    "    ans_vec = cal_sen_vec(ans_tokens)\n",
    "    \n",
    "    train_data.append(np.concatenate((ques_vec,abs_vec,ans_vec)))\n",
    "    train_label.append(1)\n",
    "    \n",
    "    \n",
    "    start, end = sorted(random.sample(range(len(QA_abs)),2))\n",
    "    false_ans = QA_abs[start:end]\n",
    "    false_tokens = nltk.word_tokenize(false_ans)\n",
    "    false_vec = cal_sen_vec(false_tokens)\n",
    "    \n",
    "    train_data.append(np.concatenate((ques_vec,abs_vec,false_vec)))\n",
    "    train_label.append(0)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_label = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_label = []\n",
    "csvFile1 = open('/home/xuhui/10002/Machine_Learning/test.csv', 'r', encoding='utf-8')\n",
    "test_file = csv.reader(csvFile1)\n",
    "\n",
    "csvFile2 = open('/home/xuhui/10002/Machine_Learning/sample.csv', 'r', encoding='utf-8')\n",
    "sample_file = csv.reader(csvFile2)\n",
    "ID2Category = {}\n",
    "for line in sample_file:\n",
    "    if sample_file.line_num == 1:\n",
    "        continue\n",
    "    ID2Category[line[0]] = line[1]\n",
    "\n",
    "for line in test_file:\n",
    "    # 忽略第一行\n",
    "    if test_file.line_num == 1:\n",
    "        continue\n",
    "    \n",
    "    ques_ID = line[1]    \n",
    "    QA_abs = line[2]\n",
    "    if ID2Category[line[0]]=='1':\n",
    "        answer_text = line[3]\n",
    "        false_answer_text = line[4]\n",
    "    elif ID2Category[line[0]]=='2':\n",
    "        answer_text = line[4]\n",
    "        false_answer_text = line[3]\n",
    "    question = get_liter_questions(ques_ID)\n",
    "    \n",
    "    ques_tokens = nltk.word_tokenize(question)\n",
    "    abs_tokens = nltk.word_tokenize(QA_abs)\n",
    "    ans_tokens = nltk.word_tokenize(answer_text)\n",
    "    \n",
    "    ques_vec = cal_sen_vec(ques_tokens)\n",
    "    abs_vec = cal_sen_vec(abs_tokens)\n",
    "    ans_vec = cal_sen_vec(ans_tokens)\n",
    "    \n",
    "    test_data.append(np.concatenate((ques_vec,abs_vec,ans_vec)))\n",
    "    test_label.append(1)\n",
    "    \n",
    "    false_ans_tokens = nltk.word_tokenize(false_answer_text)\n",
    "    false_ans_vec = cal_sen_vec(false_ans_tokens)\n",
    "    test_data.append(np.concatenate((ques_vec,abs_vec,false_ans_vec)))\n",
    "    test_label.append(0)\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhui/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=1e-06, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR=linear_model.LogisticRegression(penalty='l2',tol=1e-6,multi_class='multinomial',solver='newton-cg')\n",
    "LR.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = LR.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.565481, F1-score: 0.348324\n"
     ]
    }
   ],
   "source": [
    "precision = ((test_label==1)*(pre==1)).sum()/(pre==1).sum()\n",
    "recall = ((test_label==1)*(pre==1)).sum()/(test_label==1).sum()\n",
    "F1 = precision*recall/(precision+recall)\n",
    "print('Precision: %f, F1-score: %f'%(precision,F1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
